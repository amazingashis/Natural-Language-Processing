{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical Assignment I Ashish Adhikari.ipynb",
      "provenance": [],
      "mount_file_id": "1C8vQZnPf8baYfG2rArlY6fUh2WzQ-Frn",
      "authorship_tag": "ABX9TyNVQLu/vxZyxAtbo0wRBSi9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svir3cRLQf4r"
      },
      "source": [
        "# **Chapter 2 : Hands-On Python Natural Language Processing**\n",
        "                                                                                                       Prepared By Ashish Adhilari\n",
        "This is a practical assesement done for the for the fuilfillement for the Comp 473 i.e. Speech and Language Processing.\n",
        "The major concept of this assignment are:\n",
        "\n",
        "*   Understanding Python with NLP\n",
        "*   Important Python libraries\n",
        "*   Web scraping libraries and methodologies\n",
        "\n",
        "\n",
        " \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oALLsoSMSXiY"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF-FCbRjQa6T"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XF7WGexRvDJ"
      },
      "source": [
        "We have a CSV file with flight arrival and departure data from major US\n",
        "airports from July 2019. The data has been sourced from the US Department\n",
        "of Transportation website (https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236).\n",
        "\n",
        "All the datasets downloaded will be available in my the drive :\n",
        "https://drive.google.com/drive/folders/1VfIDw-VbfCScE4oQcZPlRBAEJfJuo2aq?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPgvowPNUabU"
      },
      "source": [
        "# Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGFj_52TUZfI",
        "outputId": "2ed06ae1-bada-4cab-ff2c-64bc40643e28"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Data/flight_data.csv\")\n",
        "#which airport has the longest average delay in terms of flight departure.\n",
        "print(\"The airport with longest delay time is:\",data.groupby(\"ORIGIN\").mean()[\"DEP_DELAY\"].idxmax())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The airport with longest delay time is: PPG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "JxOxXYXPR1I1",
        "outputId": "7c40bbd1-d461-4832-8729-7399959ac3d8"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>CARRIER</th>\n",
              "      <th>ORIGIN</th>\n",
              "      <th>DEST</th>\n",
              "      <th>SCHED_DEP_TIME</th>\n",
              "      <th>ACT_DEP_TIME</th>\n",
              "      <th>DEP_DELAY</th>\n",
              "      <th>SCHED_ARR_TIME</th>\n",
              "      <th>ACT_ARR_TIME</th>\n",
              "      <th>ARR_DELAY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>24</td>\n",
              "      <td>G4</td>\n",
              "      <td>PIE</td>\n",
              "      <td>AVL</td>\n",
              "      <td>1511</td>\n",
              "      <td>1533.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1644</td>\n",
              "      <td>1659.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>G4</td>\n",
              "      <td>AUS</td>\n",
              "      <td>SFB</td>\n",
              "      <td>2002</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2335</td>\n",
              "      <td>2344.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>G4</td>\n",
              "      <td>GRI</td>\n",
              "      <td>LAS</td>\n",
              "      <td>1118</td>\n",
              "      <td>1118.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1144</td>\n",
              "      <td>1139.0</td>\n",
              "      <td>-5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>G4</td>\n",
              "      <td>AUS</td>\n",
              "      <td>MEM</td>\n",
              "      <td>1643</td>\n",
              "      <td>1726.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1827</td>\n",
              "      <td>1922.0</td>\n",
              "      <td>55.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>G4</td>\n",
              "      <td>IND</td>\n",
              "      <td>PIE</td>\n",
              "      <td>858</td>\n",
              "      <td>905.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1107</td>\n",
              "      <td>1119.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YEAR  MONTH  DAY CARRIER  ... DEP_DELAY SCHED_ARR_TIME  ACT_ARR_TIME  ARR_DELAY\n",
              "0  2019      7   24      G4  ...      22.0           1644        1659.0       15.0\n",
              "1  2019      7   29      G4  ...       8.0           2335        2344.0        9.0\n",
              "2  2019      7    7      G4  ...       0.0           1144        1139.0       -5.0\n",
              "3  2019      7    7      G4  ...      43.0           1827        1922.0       55.0\n",
              "4  2019      7    8      G4  ...       7.0           1107        1119.0       12.0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfzEMGG-WYxG"
      },
      "source": [
        "# **Vectorization in Python using the scikit-learn**\n",
        "\n",
        "Eg. How do we change the payment method and payment frequency?\n",
        "\n",
        "We assume an N-dimensional space where each\n",
        "dimension (axis) of the space corresponds to a word from the English\n",
        "vocabulary? With this, we can represent the preceding statement as a vector\n",
        "in that space, with its coordinate along each axis being the count of the word\n",
        "representing that axis. So, in the given sentence, the sentence vector's\n",
        "magnitude along the payment axes will be 2, the frequency axes will be 1, and so\n",
        "on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwPTN2tDU3Ws",
        "outputId": "015acb5c-5131-451a-f1d3-13dcf90dba46"
      },
      "source": [
        "sentence = [\"How to change payment method and payment frequency\"]\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "vectorizer.fit_transform(sentence).todense()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1, 1, 1, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhyKo3iQY75b"
      },
      "source": [
        "# **NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXW1gYbFXTmK"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hgQTcXOZCmN",
        "outputId": "425569de-7e1a-4b51-8fc3-1013028325ec"
      },
      "source": [
        "text = \"Who would have thought that computer programs would be analyzing human sentiments \"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Who', 'would', 'have', 'thought', 'that', 'computer', 'programs', 'would', 'be', 'analyzing', 'human', 'sentiments']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgpGLCzlaAKK",
        "outputId": "4236f25a-1473-4d83-9cef-64394e0389bf"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "print(stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AH78RHpaK39",
        "outputId": "c3701e8e-6232-435e-fdca-a1f76cdc835d"
      },
      "source": [
        "newtokens=[word for word in tokens if word not in stopwords]\n",
        "print(newtokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Who', 'would', 'thought', 'computer', 'programs', 'would', 'analyzing', 'human', 'sentiments']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVmjXwY4bmG_"
      },
      "source": [
        "# **Word lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe6TfFJUblZL",
        "outputId": "c42db23a-16ec-4039-8cb4-d086a381e690"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "#nltk.download('wordnet')\n",
        "text = \"Who would have thought that computer programs would be analyzing human sentiments \"\n",
        "tokens = word_tokenize(text)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Who', 'would', 'have', 'thought', 'that', 'computer', 'program', 'would', 'be', 'analyzing', 'human', 'sentiment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvssugegcqBx"
      },
      "source": [
        "Lemmatization is performed by looking up a word in WordNet's inbuilt root\n",
        "word map. If the word is not found, it returns the input word unchanged.\n",
        "However, we can see that the performance of the lemmatizer was not good\n",
        "and it was only able to reduce programs and sentiments from their plural forms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-2D4MocczyF"
      },
      "source": [
        "# **Performing stemming**\n",
        "Stemming is similar to lemmatization but instead of looking up root words in\n",
        "a pre-built dictionary, it defines some rules based on which words are\n",
        "reduced to their root form. For example, it has a rule that states that any\n",
        "word with ing as a suffix will be reduced by removing the suffix.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqZzl4Jjcv5e",
        "outputId": "39dc264e-8b7f-44be-d0c1-cf64212dd995"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "text = \"Who would have thought that computer programs would be analyzing human sentiments\"\n",
        "tokens=word_tokenize(text.lower())\n",
        "ps = PorterStemmer()\n",
        "tokens=[ps.stem(word) for word in tokens]\n",
        "print(tokens)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['who', 'would', 'have', 'thought', 'that', 'comput', 'program', 'would', 'be', 'analyz', 'human', 'sentiment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU_B8dX9dffm"
      },
      "source": [
        "# **Part of speech tagging (POS tagging)**\n",
        "Part of speech tagging (POS tagging) identifies the part of speech (noun,\n",
        "verb, adverb, and so on) of each word in a sentence. It is a crucial step for\n",
        "many NLP applications since, by identifying the POS of a word, we can\n",
        "deduce its contextual meaning. For example, the meaning of the word\n",
        "ground is different when it is used as a noun; for example, The ground was\n",
        "sodden due to rain, compared to when it is used as an adjective, for\n",
        "example, The restaurant's ground meat recipe is quite popular. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRJU_VbEcpA9",
        "outputId": "b41dfb18-90bf-4297-a27f-20264dbadec4"
      },
      "source": [
        "#nltk.download('averaged_perceptron_tagger')\n",
        "print(nltk.pos_tag([\"your\"]))\n",
        "print(nltk.pos_tag([\"beautiful\"]))\n",
        "print(nltk.pos_tag([\"eat\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('your', 'PRP$')]\n",
            "[('beautiful', 'NN')]\n",
            "[('eat', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsUbIvo7ak6J",
        "outputId": "7321ca95-8eb7-4661-c445-9369b29b4003"
      },
      "source": [
        "text = \"Usain Bolt is the fastest runner in the world\"\n",
        "tokens = word_tokenize(text)\n",
        "[nltk.pos_tag([word]) for word in tokens]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Usain', 'NN')],\n",
              " [('Bolt', 'NN')],\n",
              " [('is', 'VBZ')],\n",
              " [('the', 'DT')],\n",
              " [('fastest', 'JJS')],\n",
              " [('runner', 'NN')],\n",
              " [('in', 'IN')],\n",
              " [('the', 'DT')],\n",
              " [('world', 'NN')]]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1O80VlJejUS",
        "outputId": "eca71d7d-eec5-43ea-f5e9-ab733420e31b"
      },
      "source": [
        "nltk.download('tagsets') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbDhylOnexmU"
      },
      "source": [
        "# **Unterstanding the Tags**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "danu_lGdep58",
        "outputId": "68b71e5a-427d-4fe1-9da8-cf5cb4e2320b"
      },
      "source": [
        "nltk.help.upenn_tagset() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$: dollar\n",
            "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
            "'': closing quotation mark\n",
            "    ' ''\n",
            "(: opening parenthesis\n",
            "    ( [ {\n",
            "): closing parenthesis\n",
            "    ) ] }\n",
            ",: comma\n",
            "    ,\n",
            "--: dash\n",
            "    --\n",
            ".: sentence terminator\n",
            "    . ! ?\n",
            ":: colon or ellipsis\n",
            "    : ; ...\n",
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n",
            "CD: numeral, cardinal\n",
            "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
            "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
            "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "EX: existential there\n",
            "    there\n",
            "FW: foreign word\n",
            "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
            "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
            "    terram fiche oui corporis ...\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n",
            "JJR: adjective, comparative\n",
            "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
            "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
            "    cozier creamier crunchier cuter ...\n",
            "JJS: adjective, superlative\n",
            "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
            "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
            "    dearest deepest densest dinkiest ...\n",
            "LS: list item marker\n",
            "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
            "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
            "    two\n",
            "MD: modal auxiliary\n",
            "    can cannot could couldn't dare may might must need ought shall should\n",
            "    shouldn't will would\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n",
            "NNPS: noun, proper, plural\n",
            "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
            "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
            "    Apache Apaches Apocrypha ...\n",
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n",
            "PDT: pre-determiner\n",
            "    all both half many quite such sure this\n",
            "POS: genitive marker\n",
            "    ' 's\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "PRP$: pronoun, possessive\n",
            "    her his mine my our ours their thy your\n",
            "RB: adverb\n",
            "    occasionally unabatingly maddeningly adventurously professedly\n",
            "    stirringly prominently technologically magisterially predominately\n",
            "    swiftly fiscally pitilessly ...\n",
            "RBR: adverb, comparative\n",
            "    further gloomier grander graver greater grimmer harder harsher\n",
            "    healthier heavier higher however larger later leaner lengthier less-\n",
            "    perfectly lesser lonelier longer louder lower more ...\n",
            "RBS: adverb, superlative\n",
            "    best biggest bluntest earliest farthest first furthest hardest\n",
            "    heartiest highest largest least less most nearest second tightest worst\n",
            "RP: particle\n",
            "    aboard about across along apart around aside at away back before behind\n",
            "    by crop down ever fast for forth from go high i.e. in into just later\n",
            "    low more off on open out over per pie raising start teeth that through\n",
            "    under unto up up-pp upon whole with you\n",
            "SYM: symbol\n",
            "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
            "TO: \"to\" as preposition or infinitive marker\n",
            "    to\n",
            "UH: interjection\n",
            "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
            "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
            "    man baby diddle hush sonuvabitch ...\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n",
            "VBD: verb, past tense\n",
            "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
            "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
            "    speculated wore appreciated contemplated ...\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "VBN: verb, past participle\n",
            "    multihulled dilapidated aerosolized chaired languished panelized used\n",
            "    experimented flourished imitated reunifed factored condensed sheared\n",
            "    unsettled primed dubbed desired ...\n",
            "VBP: verb, present tense, not 3rd person singular\n",
            "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
            "    appear tend stray glisten obtain comprise detest tease attract\n",
            "    emphasize mold postpone sever return wag ...\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
            "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
            "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
            "WDT: WH-determiner\n",
            "    that what whatever which whichever\n",
            "WP: WH-pronoun\n",
            "    that what whatever whatsoever which who whom whosoever\n",
            "WP$: WH-pronoun, possessive\n",
            "    whose\n",
            "WRB: Wh-adverb\n",
            "    how however whence whenever where whereby whereever wherein whereof why\n",
            "``: opening quotation mark\n",
            "    ` ``\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcEMb0WHfHM3"
      },
      "source": [
        "# **TextBlob**\n",
        "Textblob is a popular library used for sentiment analysis, part of speech\n",
        "tagging, translation, and so on. It is built on top of other libraries, including\n",
        "NLTK, and provides a very easy-to-use interface, making it a must-have for\n",
        "NLP beginners. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOJyWfHlfVKk"
      },
      "source": [
        "## Sentiment analysis\n",
        "Sentiment analysis is an important area of research within NLP that aims to\n",
        "analyze text and assess its sentiment. The Textblob library allows users to\n",
        "analyze the sentiment of a given piece of text in a very convenient way.\n",
        "\n",
        "\n",
        "The polarity score ranges from -1 to 1, with -1\n",
        "being the most negative sentiment and 1 being the most positive statement.\n",
        "The subjectivity score ranges from 0 to 1, with a score of 0 implying that the\n",
        "statement is factual, whereas a score of 1 implies a highly subjective\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpuIgJvoerxP",
        "outputId": "dfe8ae38-f7b8-45ea-af70-3e2956456d72"
      },
      "source": [
        "from textblob import TextBlob\n",
        "print(TextBlob(\"I love pizza\").sentiment)\n",
        "print(TextBlob(\"The weather is excellent\").sentiment)\n",
        "print(TextBlob(\"What a terrible thing to say\").sentiment)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment(polarity=0.5, subjectivity=0.6)\n",
            "Sentiment(polarity=1.0, subjectivity=1.0)\n",
            "Sentiment(polarity=-1.0, subjectivity=1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKahHzvogJ8B"
      },
      "source": [
        "# **Machine translation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "R1VBtBaAfGHN",
        "outputId": "aa0bb07a-7d3c-4885-81a9-e8f955da2d26"
      },
      "source": [
        "from textblob import TextBlob\n",
        "languages = ['fr','zh-CN','hi']\n",
        "for language in languages:\n",
        "    print(TextBlob(\"Who knew translation could be fun\").translate(to=language))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-2848b879bf96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlanguages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'fr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'zh-CN'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlanguages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Who knew translation could be fun\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/blob.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, from_lang, to)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \"\"\"\n\u001b[1;32m    546\u001b[0m         return self.__class__(self.translator.translate(self.raw,\n\u001b[0;32m--> 547\u001b[0;31m                               from_lang=from_lang, to_lang=to))\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetect_language\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/translate.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, source, from_lang, to_lang, host, type_)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_calculate_tk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         )\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/translate.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, url, host, type_, data)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhost\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMzZPbwgtVPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e0de721-be82-4603-dbb4-7992da9de0e3"
      },
      "source": [
        "TextBlob(\"The global economy is expected to grow this year\").tags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('global', 'JJ'),\n",
              " ('economy', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('expected', 'VBN'),\n",
              " ('to', 'TO'),\n",
              " ('grow', 'VB'),\n",
              " ('this', 'DT'),\n",
              " ('year', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OalOf8zdstaT"
      },
      "source": [
        "# **VADER**\n",
        "Valence Aware Dictionary and sEntiment Reasoner (VADER) is a\n",
        "recently developed lexicon-based sentiment analysis tool whose accuracy is\n",
        "shown to be much greater than the existing lexicon-based sentiment\n",
        "analyzers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47K5j25Lo92h",
        "outputId": "eb0320fe-04e8-4911-b6fa-9c036fe2d551"
      },
      "source": [
        "#!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyser = SentimentIntensityAnalyzer()\n",
        "\n",
        "analyser.polarity_scores(\"This book is very good\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.4927, 'neg': 0.0, 'neu': 0.556, 'pos': 0.444}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_0Us3AQs1hi",
        "outputId": "87ca124c-42cb-4af4-df5b-bf7a218b4dec"
      },
      "source": [
        "analyser.polarity_scores(\"OMG! The book is so cool\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.5079, 'neg': 0.0, 'neu': 0.604, 'pos': 0.396}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt8UzJ87kLIX"
      },
      "source": [
        "# **Web Scrapping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zduAdQkus69Q"
      },
      "source": [
        "#!pip install beautifulsoup4\n",
        "#!pip install requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9bifA0DVy8d"
      },
      "source": [
        "titles = []\n",
        "prices = []\n",
        "ratings = []\n",
        "url = 'https://webscraper.io/test-sites/e-commerce/allinone/computers/laptops'\n",
        "request = requests.get(url)\n",
        "soup = BeautifulSoup(request.text, \"html.parser\")\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcxlUtCHWEoF",
        "outputId": "a08989ea-bebc-4b5c-8a42-74574a032dee"
      },
      "source": [
        "for product in soup.find_all('div',{'class' : 'col-sm-4 col-lg-4 col-md-4'}):\n",
        "  #print(product)\n",
        "  for pr in product.find_all('div',{'class' : 'caption'}):\n",
        "    for p in pr.find_all('h4',{'class': 'pull-right price'}):\n",
        "      prices.append(p.text)\n",
        "    for h in pr.find_all('a',{'title'}):\n",
        "      titles.append(h.get('title'))\n",
        "      \n",
        "    \n",
        "  for rating in product.find_all('div',{'class':'ratings'}):\n",
        "    ratings.append(len(rating.find_all('span',{'class' : 'glyphicon glyphicon-star'})))\n",
        "\n",
        "\n",
        "product_df = pd.DataFrame(zip(titles,prices,ratings),columns=['Titles','Prices', 'Ratings'])\n",
        "product_df.to_csv(\"ecommerce.csv\", index = False)\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asus VivoBook X441NA-GA190\n",
            "Prestigio SmartBook 133S Dark Grey\n",
            "Prestigio SmartBook 133S Gold\n",
            "Aspire E1-510\n",
            "Lenovo V110-15IAP\n",
            "Lenovo V110-15IAP\n",
            "Hewlett Packard 250 G6 Dark Ash Silver\n",
            "Acer Aspire 3 A315-31 Black\n",
            "Acer Aspire A315-31-C33J\n",
            "Acer Aspire ES1-572 Black\n",
            "Acer Aspire 3 A315-31 Black\n",
            "Acer Aspire 3 A315-21\n",
            "Asus VivoBook Max\n",
            "Asus VivoBook E502NA-GO022T Dark Blue\n",
            "Lenovo ThinkPad E31-80\n",
            "Acer Aspire 3 A315-31 Black\n",
            "Lenovo V110-15ISK\n",
            "Acer Aspire ES1-732 Black\n",
            "Asus VivoBook 15 X540NA-GQ026T\n",
            "Packard 255 G2\n",
            "Asus EeeBook R416NA-FA014T\n",
            "Acer Aspire 3 A315-51\n",
            "Acer Aspire ES1-572 Black\n",
            "Acer Extensa 15 (2540) Black\n",
            "Acer Aspire ES1-572 Black\n",
            "Lenovo V110-15ISK\n",
            "Acer Aspire A315-51-33TG\n",
            "Lenovo V110-15IKB\n",
            "Asus VivoBook 15 X540UA-DM260 Chocolate Black\n",
            "Acer Aspire ES1-572 Black\n",
            "Lenovo V510 Black\n",
            "Acer Aspire ES1-572 Black\n",
            "Lenovo V510 Black\n",
            "Acer Swift 1 SF113-31 Silver\n",
            "Dell Vostro 15\n",
            "Acer Aspire 3 A315-51 Black\n",
            "Dell Vostro 15 (3568) Red\n",
            "Lenovo V510 Black\n",
            "HP 250 G3\n",
            "Acer Spin 5\n",
            "HP 350 G1\n",
            "Aspire E1-572G\n",
            "Pavilion\n",
            "Acer Aspire A515-51-5654\n",
            "Dell Inspiron 15\n",
            "Asus VivoBook S14\n",
            "ProBook\n",
            "Inspiron 15\n",
            "Asus ROG STRIX GL553VD-DM256\n",
            "Acer Nitro 5 AN515-51\n",
            "Asus ROG STRIX GL553VD-DM256\n",
            "Lenovo ThinkPad L570\n",
            "ThinkPad Yoga\n",
            "Lenovo ThinkPad L460\n",
            "Dell Inspiron 15 (7567) Black\n",
            "MSI GL72M 7RDX\n",
            "MSI GL72M 7RDX\n",
            "Asus ROG Strix GL553VD-DM535T\n",
            "Dell Latitude 5280\n",
            "Dell Latitude 5480\n",
            "Lenovo Legion Y520-15IKBM\n",
            "Toshiba Portege Z30-C-16J Grey\n",
            "Acer Predator Helios 300 (PH317-51)\n",
            "Acer Aspire 7 A715-71G\n",
            "Dell Inspiron 17 2in1 (7779) Silver\n",
            "Dell Latitude 5480\n",
            "Lenovo Legion Y520\n",
            "Asus AsusPro Advanced BU401LA-FA271G Dark Grey\n",
            "Acer Nitro 5 AN515-51\n",
            "Dell Latitude 5480\n",
            "Dell Inspiron 15 (7567) Black\n",
            "Dell Latitude 5580\n",
            "Lenovo Legion Y520-15IKBM\n",
            "MSI GP62M 7RDX Leopard\n",
            "Lenovo Yoga 720 Grey\n",
            "Toshiba Portege Z30-C-16L Grey\n",
            "Acer TravelMate P645-S-511A Black\n",
            "Dell Latitude 5580\n",
            "ThinkPad T540p\n",
            "MSI GS63 7RD Stealth\n",
            "Dell Latitude 5480\n",
            "Acer Predator Helios 300 (PH317-51)\n",
            "MSI GL62M 7REX\n",
            "MSI GL62M 7REX2\n",
            "Lenovo Yoga 910 Grey\n",
            "Toshiba Portege X30-D-10J Black/Blue\n",
            "Lenovo IdeaPad Miix 510 Platinum Silver\n",
            "Acer Predator Helios 300 (PH317-51)\n",
            "ThinkPad Yoga\n",
            "Asus VivoBook Pro 15 N580VN-FI006T Gold Metal\n",
            "Dell Latitude 5480\n",
            "Asus ZenBook UX530UX-FY040T Blue\n",
            "ThinkPad X230\n",
            "Asus ROG Strix GL753VE-GC096T\n",
            "Apple MacBook Air 13\"\n",
            "Dell Latitude 5480\n",
            "Hewlett Packard Spectre 13-v106na Dark Ash Silver\n",
            "Dell XPS 13\n",
            "Toshiba Portege Z30-C-16K Grey\n",
            "MSI GL62VR 7RFX\n",
            "Dell Latitude 5480\n",
            "ThinkPad X240\n",
            "Hewlett Packard ProBook 640 G3\n",
            "Apple MacBook Pro 13\" Space Gray\n",
            "Dell Latitude 5580\n",
            "Dell Latitude 5480\n",
            "Dell Latitude 5580\n",
            "Apple MacBook Air 13\"\n",
            "Lenovo ThinkPad T470\n",
            "Lenovo ThinkPad Yoga 370 Black\n",
            "Toshiba Portege X20W-D-10V Black/Blue\n",
            "Asus ASUSPRO B9440UA-GV0279R Gray\n",
            "Lenovo Legion Y720\n",
            "Asus ROG Strix GL702VM-GC146T\n",
            "Asus ROG Strix GL702ZC-GC154T\n",
            "Asus ROG Strix GL702ZC-GC209T\n",
            "Asus ROG Strix SCAR Edition GL503VM-ED115T\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t_zOoTqNXhg1",
        "outputId": "b7c56b58-b86c-4895-89d2-5e7f70668c62"
      },
      "source": [
        "product_df['Titles']"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Asus VivoBook X441NA-GA190'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "2i9Avf-_d2nj",
        "outputId": "0f64195e-361a-403d-8519-5c1f4c035fd6"
      },
      "source": [
        "product_df.head(15)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titles</th>\n",
              "      <th>Prices</th>\n",
              "      <th>Ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Asus VivoBook X441NA-GA190</td>\n",
              "      <td>$295.99</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Prestigio SmartBook 133S Dark Grey</td>\n",
              "      <td>$299.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Prestigio SmartBook 133S Gold</td>\n",
              "      <td>$299.00</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aspire E1-510</td>\n",
              "      <td>$306.99</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lenovo V110-15IAP</td>\n",
              "      <td>$321.94</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Lenovo V110-15IAP</td>\n",
              "      <td>$356.49</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Hewlett Packard 250 G6 Dark Ash Silver</td>\n",
              "      <td>$364.46</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Acer Aspire 3 A315-31 Black</td>\n",
              "      <td>$372.70</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Acer Aspire A315-31-C33J</td>\n",
              "      <td>$379.94</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Acer Aspire ES1-572 Black</td>\n",
              "      <td>$379.95</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Acer Aspire 3 A315-31 Black</td>\n",
              "      <td>$391.48</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Acer Aspire 3 A315-21</td>\n",
              "      <td>$393.88</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Asus VivoBook Max</td>\n",
              "      <td>$399.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Asus VivoBook E502NA-GO022T Dark Blue</td>\n",
              "      <td>$399.99</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Lenovo ThinkPad E31-80</td>\n",
              "      <td>$404.23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Titles   Prices  Ratings\n",
              "0               Asus VivoBook X441NA-GA190  $295.99        3\n",
              "1       Prestigio SmartBook 133S Dark Grey  $299.00        2\n",
              "2            Prestigio SmartBook 133S Gold  $299.00        4\n",
              "3                            Aspire E1-510  $306.99        3\n",
              "4                        Lenovo V110-15IAP  $321.94        3\n",
              "5                        Lenovo V110-15IAP  $356.49        2\n",
              "6   Hewlett Packard 250 G6 Dark Ash Silver  $364.46        1\n",
              "7              Acer Aspire 3 A315-31 Black  $372.70        2\n",
              "8                 Acer Aspire A315-31-C33J  $379.94        2\n",
              "9                Acer Aspire ES1-572 Black  $379.95        4\n",
              "10             Acer Aspire 3 A315-31 Black  $391.48        4\n",
              "11                   Acer Aspire 3 A315-21  $393.88        3\n",
              "12                       Asus VivoBook Max  $399.00        1\n",
              "13   Asus VivoBook E502NA-GO022T Dark Blue  $399.99        4\n",
              "14                  Lenovo ThinkPad E31-80  $404.23        1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBj0TvyNeuNJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}